"""
TEMPLATE - ETAPA 3: MODELO BASELINE
====================================

Este template guia voc√™ passo a passo na cria√ß√£o do modelo baseline.
Siga os coment√°rios e preencha os TODOs.

OBJETIVO: Criar um modelo de Regress√£o Linear simples e avaliar sua performance.
"""

# ============================================================================
# IMPORTS
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import joblib

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ============================================================================
# PASSO 1: CARREGAR DADOS LIMPOS
# ============================================================================
print("="*60)
print("ETAPA 3: MODELO BASELINE - REGRESS√ÉO LINEAR")
print("="*60)

# TODO: Ajuste o caminho para seu arquivo de dados limpos (da Etapa 2)
df = pd.read_csv('../../data/students_clean.csv')

print(f"\n‚úì Dados carregados: {df.shape[0]} linhas, {df.shape[1]} colunas")

# Visualizar primeiras linhas
print("\nPrimeiras linhas:")
print(df.head())

# ============================================================================
# PASSO 2: SEPARAR FEATURES (X) e TARGET (y)
# ============================================================================

# TODO: Ajuste o nome da coluna target de acordo com seu dataset
TARGET_COLUMN = 'final_grade'  # Mude se necess√°rio

# TODO: Liste aqui as colunas que voc√™ N√ÉO quer usar (ex: IDs, nome, etc.)
COLUNAS_REMOVER = ['student_id']  # Adicione outras se necess√°rio

# Separar X (features) e y (target)
X = df.drop(columns=[TARGET_COLUMN] + COLUNAS_REMOVER, errors='ignore')
y = df[TARGET_COLUMN]

print(f"\n‚úì Features (X): {X.shape[1]} colunas")
print(f"‚úì Target (y): {y.shape[0]} valores")
print(f"\nFeatures utilizadas:")
print(X.columns.tolist())

# ============================================================================
# PASSO 3: DIVIS√ÉO DOS DADOS (60% TREINO / 20% VALIDA√á√ÉO / 20% TESTE)
# ============================================================================

# IMPORTANTE: Usamos random_state para reprodutibilidade
RANDOM_STATE = 42

# Primeiro: separar 20% para teste (N√ÉO VAMOS USAR AGORA!)
X_temp, X_test, y_temp, y_test = train_test_split(
    X, y,
    test_size=0.2,  # 20% para teste
    random_state=RANDOM_STATE
)

# Segundo: dos 80% restantes, separar 25% para valida√ß√£o (que √© 20% do total)
# 0.25 * 0.8 = 0.2 (20% do total)
X_train, X_val, y_train, y_val = train_test_split(
    X_temp, y_temp,
    test_size=0.25,  # 25% do temp = 20% do total
    random_state=RANDOM_STATE
)

# Verificar divis√£o
total_samples = len(X)
print("\n" + "="*60)
print("DIVIS√ÉO DOS DADOS")
print("="*60)
print(f"Total de amostras: {total_samples}")
print(f"‚îú‚îÄ Treino:     {len(X_train):4d} ({len(X_train)/total_samples*100:.1f}%)")
print(f"‚îú‚îÄ Valida√ß√£o:  {len(X_val):4d} ({len(X_val)/total_samples*100:.1f}%)")
print(f"‚îî‚îÄ Teste:      {len(X_test):4d} ({len(X_test)/total_samples*100:.1f}%)")

# Verificar distribui√ß√£o do target nos 3 conjuntos
print("\nDistribui√ß√£o do target:")
print(f"‚îú‚îÄ Treino:     m√©dia={y_train.mean():.2f}, std={y_train.std():.2f}")
print(f"‚îú‚îÄ Valida√ß√£o:  m√©dia={y_val.mean():.2f}, std={y_val.std():.2f}")
print(f"‚îî‚îÄ Teste:      m√©dia={y_test.mean():.2f}, std={y_test.std():.2f}")

# Salvar datasets divididos (opcional, mas recomendado)
# TODO: Descomente se quiser salvar
# X_train.to_csv('../../data/X_train.csv', index=False)
# X_val.to_csv('../../data/X_val.csv', index=False)
# X_test.to_csv('../../data/X_test.csv', index=False)
# y_train.to_csv('../../data/y_train.csv', index=False)
# y_val.to_csv('../../data/y_val.csv', index=False)
# y_test.to_csv('../../data/y_test.csv', index=False)

# ============================================================================
# PASSO 4: CRIAR E TREINAR MODELO BASELINE (REGRESS√ÉO LINEAR)
# ============================================================================

print("\n" + "="*60)
print("TREINAMENTO DO MODELO")
print("="*60)

# Criar modelo
modelo = LinearRegression()

# Treinar modelo (fit = aprender os coeficientes)
print("\nTreinando modelo de Regress√£o Linear...")
modelo.fit(X_train, y_train)
print("‚úì Modelo treinado!")

# Visualizar coeficientes aprendidos
print("\n" + "-"*60)
print("COEFICIENTES DO MODELO")
print("-"*60)

# Criar DataFrame com features e coeficientes
coeficientes = pd.DataFrame({
    'Feature': X_train.columns,
    'Coeficiente': modelo.coef_
}).sort_values('Coeficiente', key=abs, ascending=False)

print(coeficientes.to_string(index=False))
print(f"\nIntercept (nota base): {modelo.intercept_:.4f}")

# TODO: Interprete os 3 coeficientes mais importantes
print("\nüìä Interpreta√ß√£o:")
print(f"1. {coeficientes.iloc[0]['Feature']}: {coeficientes.iloc[0]['Coeficiente']:+.3f}")
print(f"   ‚Üí Cada unidade a mais = {coeficientes.iloc[0]['Coeficiente']:+.3f} pontos na nota")
print(f"2. {coeficientes.iloc[1]['Feature']}: {coeficientes.iloc[1]['Coeficiente']:+.3f}")
print(f"3. {coeficientes.iloc[2]['Feature']}: {coeficientes.iloc[2]['Coeficiente']:+.3f}")

# ============================================================================
# PASSO 5: FAZER PREVIS√ïES
# ============================================================================

# Fazer previs√µes no treino
y_train_pred = modelo.predict(X_train)

# Fazer previs√µes na valida√ß√£o
y_val_pred = modelo.predict(X_val)

print("\n‚úì Previs√µes realizadas em treino e valida√ß√£o")

# ============================================================================
# PASSO 6: CALCULAR M√âTRICAS DE AVALIA√á√ÉO
# ============================================================================

def calcular_metricas(y_true, y_pred, dataset_name=""):
    """
    Calcula e exibe m√©tricas de regress√£o.

    Par√¢metros:
        y_true: valores reais
        y_pred: valores previstos
        dataset_name: nome do conjunto (ex: "Treino", "Valida√ß√£o")

    Retorna:
        dict com as m√©tricas
    """
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"\n{dataset_name}")
    print("-" * 40)
    print(f"MSE  (Mean Squared Error):     {mse:.4f}")
    print(f"RMSE (Root Mean Squared Error):{rmse:.4f}")
    print(f"MAE  (Mean Absolute Error):    {mae:.4f}")
    print(f"R¬≤   (R-squared):              {r2:.4f}")

    return {
        'MSE': mse,
        'RMSE': rmse,
        'MAE': mae,
        'R¬≤': r2
    }

# Calcular m√©tricas
print("\n" + "="*60)
print("M√âTRICAS DE PERFORMANCE")
print("="*60)

metricas_treino = calcular_metricas(y_train, y_train_pred, "TREINO")
metricas_val = calcular_metricas(y_val, y_val_pred, "VALIDA√á√ÉO")

# Compara√ß√£o lado a lado
print("\n" + "="*60)
print("COMPARA√á√ÉO TREINO vs VALIDA√á√ÉO")
print("="*60)

comparacao = pd.DataFrame({
    'Treino': metricas_treino,
    'Valida√ß√£o': metricas_val
})
comparacao['Diferen√ßa'] = abs(comparacao['Treino'] - comparacao['Valida√ß√£o'])

print(comparacao)

# An√°lise de Overfitting
diferenca_r2 = abs(metricas_treino['R¬≤'] - metricas_val['R¬≤'])
print("\nüìä An√°lise de Overfitting:")
if diferenca_r2 < 0.05:
    print(f"‚úÖ Excelente! Diferen√ßa R¬≤ = {diferenca_r2:.3f} (< 0.05)")
    print("   O modelo generaliza muito bem!")
elif diferenca_r2 < 0.10:
    print(f"‚úÖ Bom! Diferen√ßa R¬≤ = {diferenca_r2:.3f} (< 0.10)")
    print("   O modelo generaliza bem.")
elif diferenca_r2 < 0.20:
    print(f"‚ö†Ô∏è  Aten√ß√£o! Diferen√ßa R¬≤ = {diferenca_r2:.3f} (< 0.20)")
    print("   H√° algum overfitting, mas aceit√°vel.")
else:
    print(f"‚ùå Problema! Diferen√ßa R¬≤ = {diferenca_r2:.3f} (> 0.20)")
    print("   Overfitting significativo detectado!")

# TODO: Interprete o R¬≤ de valida√ß√£o
r2_val = metricas_val['R¬≤']
print(f"\nüìä Interpreta√ß√£o do R¬≤:")
print(f"R¬≤ = {r2_val:.3f} significa que o modelo explica {r2_val*100:.1f}% da varia√ß√£o no target.")

# ============================================================================
# PASSO 7: VISUALIZA√á√ïES
# ============================================================================

print("\n" + "="*60)
print("CRIANDO VISUALIZA√á√ïES")
print("="*60)

# GR√ÅFICO 1: Predi√ß√µes vs Valores Reais (OBRIGAT√ìRIO)
plt.figure(figsize=(10, 6))
plt.scatter(y_val, y_val_pred, alpha=0.6, edgecolors='k', linewidth=0.5)

# Linha diagonal (predi√ß√£o perfeita)
min_val = min(y_val.min(), y_val_pred.min())
max_val = max(y_val.max(), y_val_pred.max())
plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='Predi√ß√£o Perfeita')

plt.xlabel('Valores Reais', fontsize=12)
plt.ylabel('Valores Previstos', fontsize=12)
plt.title(f'Predi√ß√µes vs Valores Reais - Valida√ß√£o (R¬≤={r2_val:.3f})', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3)
plt.tight_layout()

# TODO: Ajuste o caminho para salvar
plt.savefig('predicoes_vs_real.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico 1 salvo: predicoes_vs_real.png")
plt.show()

# GR√ÅFICO 2: Distribui√ß√£o dos Res√≠duos (RECOMENDADO)
residuos = y_val - y_val_pred

plt.figure(figsize=(10, 6))
plt.hist(residuos, bins=30, edgecolor='black', alpha=0.7)
plt.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero (ideal)')
plt.xlabel('Res√≠duos (Real - Previsto)', fontsize=12)
plt.ylabel('Frequ√™ncia', fontsize=12)
plt.title(f'Distribui√ß√£o dos Res√≠duos (m√©dia={residuos.mean():.3f})', fontsize=14, fontweight='bold')
plt.legend()
plt.grid(True, alpha=0.3, axis='y')
plt.tight_layout()

# TODO: Ajuste o caminho para salvar
plt.savefig('distribuicao_residuos.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico 2 salvo: distribuicao_residuos.png")
plt.show()

# GR√ÅFICO 3: Import√¢ncia das Features (OPCIONAL)
plt.figure(figsize=(10, 8))
coef_plot = coeficientes.head(10)  # Top 10
plt.barh(coef_plot['Feature'], coef_plot['Coeficiente'])
plt.xlabel('Coeficiente', fontsize=12)
plt.ylabel('Feature', fontsize=12)
plt.title('Top 10 Features Mais Importantes', fontsize=14, fontweight='bold')
plt.axvline(0, color='black', linestyle='-', linewidth=0.5)
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()

# TODO: Ajuste o caminho para salvar
plt.savefig('importancia_features.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico 3 salvo: importancia_features.png")
plt.show()

# ============================================================================
# PASSO 8: AN√ÅLISE DE RES√çDUOS
# ============================================================================

print("\n" + "="*60)
print("AN√ÅLISE DE RES√çDUOS")
print("="*60)

print(f"\nEstat√≠sticas dos Res√≠duos (Valida√ß√£o):")
print(f"‚îú‚îÄ M√©dia:         {residuos.mean():+.4f}  (ideal: ~0)")
print(f"‚îú‚îÄ Mediana:       {residuos.median():+.4f}")
print(f"‚îú‚îÄ Desvio Padr√£o: {residuos.std():.4f}")
print(f"‚îú‚îÄ M√≠nimo:        {residuos.min():+.4f}")
print(f"‚îî‚îÄ M√°ximo:        {residuos.max():+.4f}")

# Verificar normalidade (teste visual)
if abs(residuos.mean()) < 0.1:
    print("\n‚úÖ Res√≠duos centrados em zero (m√©dia ‚âà 0)")
else:
    print(f"\n‚ö†Ô∏è  Res√≠duos N√ÉO centrados (m√©dia = {residuos.mean():.3f})")
    print("   Isso pode indicar vi√©s no modelo.")

# ============================================================================
# PASSO 9: SALVAR MODELO
# ============================================================================

print("\n" + "="*60)
print("SALVANDO MODELO")
print("="*60)

# TODO: Ajuste o caminho onde quer salvar
modelo_path = 'baseline_model.pkl'
joblib.dump(modelo, modelo_path)
print(f"‚úì Modelo salvo em: {modelo_path}")

# Para carregar depois:
# modelo_carregado = joblib.load('baseline_model.pkl')

# ============================================================================
# PASSO 10: RESUMO FINAL
# ============================================================================

print("\n" + "="*60)
print("RESUMO FINAL")
print("="*60)

print(f"""
üìä M√âTRICAS DE VALIDA√á√ÉO:
   ‚îú‚îÄ R¬≤:   {metricas_val['R¬≤']:.3f} ({metricas_val['R¬≤']*100:.1f}% da vari√¢ncia explicada)
   ‚îú‚îÄ RMSE: {metricas_val['RMSE']:.3f} (erro m√©dio em unidades do target)
   ‚îî‚îÄ MAE:  {metricas_val['MAE']:.3f}

üéØ OVERFITTING:
   ‚îî‚îÄ Diferen√ßa R¬≤: {diferenca_r2:.3f} ({'OK' if diferenca_r2 < 0.10 else 'ATEN√á√ÉO!'})

üìà TOP 3 FEATURES IMPORTANTES:
   1. {coeficientes.iloc[0]['Feature']}: {coeficientes.iloc[0]['Coeficiente']:+.3f}
   2. {coeficientes.iloc[1]['Feature']}: {coeficientes.iloc[1]['Coeficiente']:+.3f}
   3. {coeficientes.iloc[2]['Feature']}: {coeficientes.iloc[2]['Coeficiente']:+.3f}

üíæ ARQUIVOS GERADOS:
   ‚îú‚îÄ predicoes_vs_real.png
   ‚îú‚îÄ distribuicao_residuos.png
   ‚îú‚îÄ importancia_features.png
   ‚îî‚îÄ baseline_model.pkl
""")

print("="*60)
print("‚úÖ ETAPA 3 CONCLU√çDA!")
print("="*60)

# ============================================================================
# PR√ìXIMOS PASSOS
# ============================================================================

print("""
üìù PR√ìXIMOS PASSOS:

1. Documente seus resultados no relat√≥rio (GUIA_STORYTELLING.md)
2. Interprete as m√©tricas e os coeficientes
3. Analise os gr√°ficos gerados
4. Identifique pontos de melhoria para a Etapa 4

üéØ META PARA ETAPA 4:
   - Superar R¬≤ = {:.3f}
   - Reduzir RMSE < {:.3f}
   - Testar modelos mais complexos (Random Forest, XGBoost)
""".format(metricas_val['R¬≤'], metricas_val['RMSE']))

print("\nBom trabalho! üöÄ")
